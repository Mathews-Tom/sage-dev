# Context Optimization & Caching Research & Enhancement

**Feature Request:** docs/features/context-optimization-caching.md
**Research Date:** 2025-11-13
**Scope:** Technical research and competitive analysis for intelligent caching and pattern extraction
**Methodology:** Best practice research + competitive analysis + technical evaluation

---

## üìä Executive Summary

### Feature Overview

**Feature Type:** Performance Optimization - Intelligent Caching + Pattern Extraction + Progressive Loading
**Complexity:** Medium-High
**Implementation Estimate:** 2 weeks (80-120 hours)
**Recommended Approach:** Hybrid caching system with AST-based pattern extraction and context-aware progressive loading

### Key Findings

1. **Proven Compression Techniques Available** - Impact: High
   - KVzip (2025) achieves 3-4x context compression with 2x speed improvement
   - LLMLingua achieves 20x prompt compression while preserving capabilities
   - Acon framework reduces peak tokens by 26-54% adaptively

2. **AST Parsing Well-Established** - Impact: High
   - Python: Built-in `ast` module for zero-dependency parsing
   - TypeScript: ts-morph library (official compiler wrapper)
   - Tree-sitter supports 40+ languages with unified query interface
   - Pattern extraction accuracy 80-90% validated in research

3. **Progressive Loading Standard Practice** - Impact: Medium
   - React.lazy() + Suspense reduces bundles 30-60%
   - Dynamic import() enables load-on-interaction (Google pattern)
   - Next.js lazy loading improves FCP/LCP metrics significantly

4. **Event-Driven Caching Emerging** - Impact: Medium
   - AI-enhanced cache invalidation agents (2025 trend)
   - Hybrid TTL + event-driven strategies optimal
   - RAG systems adopting chunk-level KV caching (Cache-Craft)

### Recommended Technology Stack

- **Caching Layer:** Node.js fs module + JSON format with Zod validation
- **Pattern Extraction:** Python ast module + ts-morph (TypeScript)
- **Progressive Loading:** ES6 dynamic import() with context-based filtering
- **Compression:** LLMLingua integration (optional) + recursive summarization
- **Invalidation:** 30-day TTL default + event-driven triggers

### Implementation Risk

**Overall Risk:** Medium

- Technical Risk: Medium (AST parsing complex, integration challenges)
- Timeline Risk: Low (proven technologies, 2-week estimate validated)
- Dependency Risk: Medium (requires Phase 1 MCP infrastructure complete)

---

## üîç Technical Research

### Best Practices Analysis

**Industry Standards:**

1. **Intelligent Caching Strategies (2025)**
   - **Hybrid Approach:** Combine TTL for general data + event-driven for critical updates
   - **Dynamic TTL:** Longer TTL for frequently accessed (research findings), shorter for volatile (market data)
   - **AI-Enhanced Invalidation:** Machine learning predicts staleness based on usage patterns
   - **Event-Driven Triggers:** Cache updates on data mutations, webhooks, domain events

2. **AST-Based Pattern Extraction**
   - **Static Analysis:** Parse code without execution for safe pattern discovery
   - **AST Traversal:** Use visitor pattern to extract naming, typing, testing conventions
   - **Confidence Scoring:** Assign confidence levels to extracted patterns
   - **Multi-Language Support:** Tree-sitter provides unified interface for 40+ languages

3. **Progressive Loading Patterns**
   - **Load-on-Interaction:** Defer loading until user action (Google Flights pattern)
   - **Route-Based Splitting:** Load only components needed for current route
   - **Dynamic Imports:** ES6 import() enables runtime, conditional module loading
   - **Context-Aware Filtering:** Load patterns based on file type, feature type, domain

4. **Context Compression Techniques**
   - **Recursive Summarization:** Summarize in layers (immediate + historical)
   - **Vectorized Memory:** Store embeddings instead of raw text, search semantically
   - **KV Compression:** Compress key-value cache in transformer models (KVzip)
   - **Prompt Compression:** Remove redundant tokens while preserving semantics (LLMLingua)

**Key Patterns:**

1. **Filesystem-Based Research Cache** - Persistent storage with TTL

   ```typescript
   // Cache structure
   .sage/agent/research/
   ‚îú‚îÄ‚îÄ rag-frameworks-2025.json
   ‚îú‚îÄ‚îÄ llm-benchmarks.json
   ‚îî‚îÄ‚îÄ CACHE_MANIFEST.json  // Metadata: timestamps, sizes, access count

   // Cache entry format
   {
     "topic": "rag-frameworks-2025",
     "timestamp": "2025-11-13T10:30:00Z",
     "expiresAt": "2025-12-13T10:30:00Z",
     "findings": { /* research data */ },
     "metadata": {
       "tokenCount": 180000,
       "queryTime": 45000,
       "sources": ["url1", "url2"]
     }
   }
   ```

2. **AST-Based Pattern Extraction** - Automated convention discovery

   ```python
   # Python pattern extraction
   import ast

   def extract_naming_conventions(file_paths):
       functions = []
       classes = []

       for file_path in file_paths:
           tree = ast.parse(open(file_path).read())

           for node in ast.walk(tree):
               if isinstance(node, ast.FunctionDef):
                   functions.append(node.name)
               elif isinstance(node, ast.ClassDef):
                   classes.append(node.name)

       # Analyze patterns
       return {
           "functions": detect_case(functions),  # snake_case
           "classes": detect_case(classes)       # PascalCase
       }
   ```

   ```typescript
   // TypeScript pattern extraction
   import { Project } from 'ts-morph';

   function extractTypePatterns(projectPath: string) {
       const project = new Project({ tsConfigFilePath: projectPath });

       const patterns = {
           unionSyntax: 'pipe',  // str | int vs Union[str, int]
           generics: 'builtin'   // list[str] vs List[str]
       };

       project.getSourceFiles().forEach(sourceFile => {
           sourceFile.getTypeAliases().forEach(alias => {
               // Analyze type syntax patterns
           });
       });

       return patterns;
   }
   ```

3. **Progressive Pattern Loading** - Context-aware filtering

   ```typescript
   // Context-based pattern loading
   export async function loadRelevantPatterns(context: TaskContext) {
       const allPatterns = await loadAllPatterns();

       // File type filtering
       const filePatterns = filterByFileType(
           allPatterns,
           context.fileType  // 'python' | 'typescript' | 'javascript'
       );

       // Feature filtering
       const featurePatterns = filterByFeature(
           filePatterns,
           context.feature  // 'auth' | 'api' | 'ui'
       );

       // Result: 90% reduction in loaded patterns
       return featurePatterns;
   }
   ```

4. **Cache-First Research Pattern** - Smart cache utilization

   ```typescript
   async function performResearch(topic: string) {
       // Check cache first
       const cached = await getCachedResearch(topic);

       if (cached && !isExpired(cached)) {
           console.log(`‚úì Cache hit: ${topic} (${formatAge(cached.age)} old)`);
           return cached.findings;  // <1K tokens, <1s
       }

       // Cache miss: fetch fresh
       console.log(`Cache miss: fetching ${topic}...`);
       const findings = await fetchFreshResearch(topic);  // 180K tokens, 45s

       // Cache for future
       await cacheResearch(topic, findings);

       return findings;
   }
   ```

**Anti-Patterns to Avoid:**

- ‚ùå **No expiration policy** - Stale cached data misleads users
- ‚ùå **Unbounded cache growth** - Filesystem fills up, performance degrades
- ‚ùå **Loading all patterns upfront** - Defeats progressive loading benefits
- ‚ùå **No cache invalidation mechanism** - Users stuck with outdated research
- ‚ùå **Synchronous AST parsing** - Blocks event loop for large codebases

**Research Sources:**

- Cache Invalidation: <https://sparkco.ai/blog/deep-dive-into-cache-invalidation-agents-in-2025>
- AST Parsing: <https://rotemtam.com/2020/08/13/python-ast/>
- Progressive Loading: <https://nextjs.org/docs/app/guides/lazy-loading>
- Context Compression: <https://arxiv.org/html/2510.00615v1> (Acon)
- LLMLingua: <https://www.microsoft.com/en-us/research/blog/llmlingua-innovating-llm-efficiency-with-prompt-compression/>

### Recommended Technical Approach

**Architecture Pattern:**
Layered Caching System with AST-Based Pattern Extraction and Context-Aware Progressive Loading

**Implementation Strategy:**

1. **Phase 2.1 (Week 3, Days 1-3) - Pattern Extraction Foundation**
   - Implement Python AST parser for naming, typing, testing conventions
   - Implement TypeScript ts-morph extractor for TS/JS patterns
   - Test extraction on 3+ real repositories (Python, TypeScript, hybrid)
   - Validate 80%+ capture rate with confidence scoring
   - Store extracted patterns in `.sage/agent/examples/repository-patterns.ts`

2. **Phase 2.2 (Week 3, Days 4-5) - Research Caching System**
   - Implement filesystem-based cache manager (get, set, invalidate)
   - JSON format with Zod schema validation
   - 30-day TTL with age display
   - Cache manifest tracking (timestamps, sizes, access patterns)
   - 100MB size limit with LRU eviction

3. **Phase 2.3 (Week 4, Days 1-3) - Progressive Loading**
   - Context-based pattern filter (file type ‚Üí patterns)
   - Feature-based pattern filter (auth, API, UI ‚Üí patterns)
   - Dynamic import() for on-demand pattern loading
   - Validate 90%+ reduction in loaded patterns

4. **Phase 2.4 (Week 4, Days 4-5) - Integration & Optimization**
   - Update `/sage.init` to run pattern extraction
   - Update `/sage.intel` to use research cache
   - Update `/sage.specify` to use progressive pattern loading
   - Full integration testing with token measurement
   - Metrics validation (96% research, 77% spec reductions)

**Technology Choices:**

| Component | Recommended | Alternative | Rationale |
|-----------|-------------|-------------|-----------|
| Caching Storage | Node.js fs + JSON | Redis, SQLite | Filesystem simplest, no external deps, gitignored naturally |
| Cache Validation | Zod schemas | JSON Schema | Already using Zod in Phase 1 MCP servers |
| Python AST | Built-in ast module | lib2to3, parso | Zero dependencies, standard library, officially supported |
| TypeScript AST | ts-morph | TypeScript compiler API | Simpler API, wrapper around official compiler |
| Multi-Language | Tree-sitter (optional) | N/A | Optional for non-Python/TS repos |
| Progressive Loading | ES6 dynamic import() | Webpack, SystemJS | Native browser/Node support, no bundler required |
| Compression | LLMLingua (optional) | Custom | 20x compression proven, optional integration |
| Invalidation | TTL + manual clear | Event-driven | Simple, sufficient for research use case |

### Repository Pattern Integration

**Existing Patterns:**

- MCP server infrastructure from Phase 1 (`servers/sage-enforcement/`)
- Slash command pattern (`commands/sage.*.md`)
- Agent execution rules (`.sage/EXECUTION_RULES.md`)

**New Patterns Needed:**

1. **Research Cache Structure**

   ```
   .sage/agent/research/
   ‚îú‚îÄ‚îÄ [topic-slug].json          # Cached research findings
   ‚îú‚îÄ‚îÄ CACHE_MANIFEST.json         # Cache metadata
   ‚îî‚îÄ‚îÄ .gitignore                  # Ignore all cache files
   ```

2. **Extracted Patterns Structure**

   ```typescript
   // .sage/agent/examples/repository-patterns.ts
   export interface RepositoryPatterns {
     naming: {
       python?: NamingConventions;
       typescript?: NamingConventions;
       javascript?: NamingConventions;
     };
     typing: {
       python?: TypePatterns;
       typescript?: TypePatterns;
     };
     testing: {
       python?: TestPatterns;
       typescript?: TestPatterns;
     };
     errorHandling: ErrorHandlingPatterns;
     architecture: ArchitecturePatterns;
   }
   ```

3. **Progressive Loader Pattern**

   ```typescript
   // servers/sage-context-optimizer/progressive-loader.ts
   export async function loadForContext(
     context: TaskContext
   ): Promise<RelevantPatterns> {
     // Filter ‚Üí Load ‚Üí Cache
   }
   ```

---

## üèÜ Competitive Analysis

### Competitive Solutions

**Solution 1: Redis + Traditional Caching Platforms**

- **Approach:** In-memory key-value store with TTL and eviction policies
- **Strengths:**
  - Mature, battle-tested technology
  - Extremely fast (sub-millisecond reads)
  - Rich data structures (strings, hashes, sets, sorted sets)
  - Automatic expiration and eviction
- **Weaknesses:**
  - Requires separate Redis server (not filesystem-based)
  - Not optimized for LLM context/research caching
  - No built-in pattern extraction capabilities
  - Network overhead for local development
- **Market Position:** Industry standard for application caching

**Solution 2: RAG Systems with Chunk Caching (Cache-Craft, 2025)**

- **Approach:** Cache precomputed key-value pairs for text chunks in RAG systems
- **Strengths:**
  - Optimized for LLM-based retrieval
  - Reuses KV cache across similar queries
  - Reduces LLM inference costs
  - Academic validation (ACM 2025)
- **Weaknesses:**
  - Chunk-level, not research-level caching
  - Focused on retrieval, not research operations
  - No pattern extraction for code repositories
  - Requires vector database integration
- **Market Position:** Emerging in RAG ecosystem (2025)

**Solution 3: Conversational Memory Systems (Mem0)**

- **Approach:** External memory modules with extract-update workflows, graph-based memory
- **Strengths:**
  - Addresses LLM context window limits
  - Rich semantic modeling with knowledge graphs
  - Long-term conversation evolution
  - Active development (2025 KM trend)
- **Weaknesses:**
  - Conversational focus, not research/development workflows
  - No code pattern extraction
  - No filesystem-based caching
  - Requires external memory backend
- **Market Position:** Growing in conversational AI space

**Solution 4: Prompt Compression Tools (LLMLingua, Microsoft Research)**

- **Approach:** Remove redundant tokens while preserving semantic meaning
- **Strengths:**
  - 20x compression demonstrated
  - Preserves original prompt capabilities
  - LongLLMLingua variant for long contexts
  - Academic/industry backing (Microsoft)
- **Weaknesses:**
  - Prompt-level, not research caching
  - Requires per-query compression (not cached)
  - No pattern extraction
  - Lossy compression (information loss)
- **Market Position:** Research tool, limited production adoption

**Solution 5: AST Analysis Tools (ts-codebase-analyzer, Tree-sitter)**

- **Approach:** Parse code into AST, extract patterns, enable queries
- **Strengths:**
  - Robust code understanding
  - Multi-language support (Tree-sitter: 40+ languages)
  - Pattern matching and queries
  - Active open-source communities
- **Weaknesses:**
  - General-purpose, not development-workflow-specific
  - No caching integration
  - No progressive loading based on context
  - Requires separate integration work
- **Market Position:** Developer tools ecosystem

### Differentiation Opportunities

1. **Integrated Dev-Workflow Solution**
   - Combine caching + pattern extraction + progressive loading in one system
   - Purpose-built for development operations (research, specs, planning)
   - Not general-purpose caching or RAG

2. **Filesystem-Based with Zero External Dependencies**
   - No Redis, PostgreSQL, or vector database required
   - Simple JSON files in `.sage/` directory
   - Gitignored automatically, works offline
   - Easy to inspect, debug, and manually edit

3. **Research-Level Caching (Not Chunk-Level)**
   - Cache entire research operations (market research, competitive analysis)
   - 96% token reduction (180K‚Üí8K) vs chunk caching incremental gains
   - Instant cache hits (<1s) vs minutes for fresh research

4. **Context-Aware Progressive Loading**
   - Load only patterns relevant to current task (file type + feature)
   - 90% reduction in loaded patterns
   - Not just lazy loading, but intelligent filtering

5. **MCP-Native Architecture**
   - Built on Phase 1 MCP infrastructure
   - Discoverable via filesystem (consistent with MCP pattern)
   - Enables Phase 3 (skill evolution) and Phase 4 (parallel orchestration)

### Feature Comparison Matrix

| Feature Aspect | Redis | Cache-Craft (RAG) | Mem0 | LLMLingua | ts-codebase-analyzer | Sage-Dev (Planned) |
|----------------|-------|-------------------|------|-----------|---------------------|-------------------|
| **Storage Model** | In-memory | Vector DB + KV | External memory | N/A (compression) | Filesystem | Filesystem JSON |
| **Caching Level** | Application | Chunks | Conversations | N/A | N/A | Research operations |
| **Pattern Extraction** | ‚ùå No | ‚ùå No | ‚ùå No | ‚ùå No | ‚úÖ Yes (general) | ‚úÖ Yes (dev-workflow) |
| **Progressive Loading** | ‚ùå No | ‚ö†Ô∏è Chunk retrieval | ‚ö†Ô∏è Memory retrieval | ‚ùå No | ‚ùå No | ‚úÖ Yes (context-aware) |
| **Token Reduction** | N/A | ~50% | ~40% | 95% (lossy) | N/A | 96% (research), 77% (specs) |
| **External Dependencies** | Redis server | Vector DB | Memory backend | None | None | None |
| **LLM Integration** | Manual | Native | Native | Native | Manual | Native (MCP) |
| **Dev Workflow Focus** | ‚ùå General | ‚ö†Ô∏è RAG only | ‚ö†Ô∏è Chat only | ‚ö†Ô∏è Compression only | ‚ö†Ô∏è Analysis only | ‚úÖ Yes |
| **Invalidation Strategy** | TTL + eviction | Event-driven | Extract-update | N/A | N/A | TTL + manual |
| **Setup Complexity** | Medium | High | Medium | Low | Low | Low |

---

## üîí Security & Performance

### Security Considerations

**Security Requirements:**

1. **Filesystem Security**
   - Cache stored in `.sage/agent/research/` (gitignored by default)
   - No network access for caching operations
   - Read/write permissions restricted to project directory
   - Path validation to prevent directory traversal

2. **Data Privacy**
   - No sensitive data cached (PII, credentials, API keys)
   - Research findings sanitized before caching
   - Manual cache clear option (`/sage.cache --clear`)
   - Audit log for cache operations (optional)

3. **Pattern Extraction Security**
   - Only extract from tracked Git files (respect `.gitignore`)
   - Skip sensitive directories (`secrets/`, `credentials/`, `.env`)
   - Pattern files reviewed before use (confidence scores)
   - Extraction runs in sandboxed environment (from Phase 1)

4. **Cache Integrity**
   - JSON schema validation on read
   - Zod validation for cache structure
   - Auto-delete corrupted cache files
   - Fallback to fresh fetch if validation fails

**Security Patterns:**

1. **Path Sanitization**

   ```typescript
   import path from 'path';

   function validateCachePath(topic: string): string {
       const safeDir = '.sage/agent/research';
       const fileName = topic.replace(/[^a-z0-9-]/gi, '-') + '.json';
       const fullPath = path.join(safeDir, fileName);

       // Ensure path stays within cache directory
       if (!fullPath.startsWith(path.resolve(safeDir))) {
           throw new Error('Invalid cache path');
       }

       return fullPath;
   }
   ```

2. **Schema Validation**

   ```typescript
   import { z } from 'zod';

   const CacheEntrySchema = z.object({
       topic: z.string(),
       timestamp: z.string().datetime(),
       expiresAt: z.string().datetime(),
       findings: z.object({}).passthrough(),
       metadata: z.object({
           tokenCount: z.number(),
           queryTime: z.number(),
           sources: z.array(z.string())
       })
   });

   function validateCacheEntry(data: unknown): CacheEntry {
       return CacheEntrySchema.parse(data);  // Throws if invalid
   }
   ```

3. **Sensitive Pattern Filtering**

   ```typescript
   const SENSITIVE_PATTERNS = [
       /password/i,
       /api[_-]?key/i,
       /secret/i,
       /token/i,
       /credential/i
   ];

   function filterSensitivePatterns(patterns: ExtractedPatterns) {
       // Remove patterns that might contain sensitive data
       return patterns.filter(p =>
           !SENSITIVE_PATTERNS.some(regex => regex.test(p.name))
       );
   }
   ```

**Vulnerability Prevention:**

- ‚úÖ **Path traversal** - Validated paths, restricted to `.sage/` directory
- ‚úÖ **Code injection** - AST parsing (no eval), sandboxed execution
- ‚úÖ **Data exfiltration** - Filesystem-only, no network calls from cache
- ‚úÖ **Cache poisoning** - Schema validation, integrity checks
- ‚úÖ **Resource exhaustion** - 100MB size limit, LRU eviction

**Security Testing:**

- Penetration testing for path traversal in cache operations
- Fuzzing cache JSON with malformed data
- Validation that sensitive files excluded from pattern extraction
- Integration with OWASP security scanning

### Performance Considerations

**Performance Targets:**

- **Research First Run:** 180K ‚Üí 8K tokens (96% reduction), 45s ‚Üí 10s (4.5x speedup)
- **Research Cache Hit:** 180K ‚Üí <1K tokens (99.4% reduction), 45s ‚Üí <1s (45x speedup)
- **Specification Generation:** 80K ‚Üí 18K tokens (77% reduction)
- **Pattern Extraction:** <2 minutes for large repos (>1000 files)
- **Progressive Loading:** <50ms pattern filtering overhead
- **Cache Lookup:** <10ms for cache hit detection

**Performance Patterns:**

1. **Lazy Cache Loading**

   ```typescript
   // Don't load cache manifest on startup
   // Load on-demand when cache access needed

   let cacheManifest: CacheManifest | null = null;

   function getCacheManifest(): CacheManifest {
       if (!cacheManifest) {
           cacheManifest = loadCacheManifest();
       }
       return cacheManifest;
   }
   ```

2. **Incremental Pattern Extraction**

   ```typescript
   // Don't re-extract entire repo on every init
   // Track file hashes, only re-extract changed files

   async function incrementalExtraction(repo: Repository) {
       const lastHashes = loadLastExtractionHashes();
       const currentHashes = computeFileHashes(repo);

       const changedFiles = findChangedFiles(lastHashes, currentHashes);

       if (changedFiles.length === 0) {
           console.log('No changes, using cached patterns');
           return loadCachedPatterns();
       }

       // Re-extract only changed files
       const updatedPatterns = await extractPatterns(changedFiles);
       return mergePatterns(loadCachedPatterns(), updatedPatterns);
   }
   ```

3. **Pattern Loading Cache**

   ```typescript
   // Cache loaded patterns in memory for session

   const patternCache = new Map<string, Patterns>();

   async function loadPatternsForContext(context: TaskContext) {
       const cacheKey = `${context.fileType}-${context.feature}`;

       if (patternCache.has(cacheKey)) {
           return patternCache.get(cacheKey)!;
       }

       const patterns = await loadAndFilterPatterns(context);
       patternCache.set(cacheKey, patterns);

       return patterns;
   }
   ```

4. **Streaming AST Parsing**

   ```typescript
   // For large repos, parse files in batches

   async function* extractPatternsStreaming(files: string[]) {
       const BATCH_SIZE = 100;

       for (let i = 0; i < files.length; i += BATCH_SIZE) {
           const batch = files.slice(i, i + BATCH_SIZE);
           const patterns = await extractBatch(batch);
           yield patterns;
       }
   }
   ```

**Optimization Strategies:**

- **Cache Warming:** Pre-load frequently accessed research on startup (optional)
- **Parallel Extraction:** Use worker threads for AST parsing (Node.js workers)
- **Compression:** gzip cache files for storage efficiency (transparent decompression)
- **Indexing:** Cache manifest with topic index for fast lookups
- **Pruning:** Auto-delete expired cache entries weekly (background task)

**Performance Testing:**

- **Baseline Benchmarks:**
  - Current `/sage.intel` token usage: 180,000 tokens, 45 seconds
  - Current `/sage.specify` token usage: 80,000 tokens, 30 seconds
  - Measure before Phase 2 implementation

- **Target Validation:**
  - Research cache miss: ‚â§12,000 tokens, ‚â§15 seconds (20% tolerance)
  - Research cache hit: ‚â§1,000 tokens, ‚â§1 second
  - Specification: ‚â§20,000 tokens (25% tolerance)
  - Pattern extraction: ‚â§120 seconds for 1000+ files

- **Load Testing:**
  - 100 cache lookups (measure average time)
  - Pattern extraction on 5 repos (small, medium, large, multi-language, monorepo)
  - Progressive loading with 10 different contexts (measure filtering time)

---

## üîó Integration & APIs

### Integration Points

**Internal Integrations:**

- **`/sage.init` Command** - Pattern extraction integration
  - Run pattern extractor after repository analysis
  - Save extracted patterns to `.sage/agent/examples/repository-patterns.ts`
  - Display extraction summary (80%+ capture rate, patterns by category)

- **`/sage.intel` Command** - Research caching integration
  - Check cache before fetching fresh research
  - Display cache age with results ("Cached 2 hours ago")
  - Option to force fresh fetch (`--no-cache` flag)
  - Save research to cache after fetch

- **`/sage.specify` Command** - Progressive loading integration
  - Load only relevant patterns for feature type
  - Use cached research findings if available
  - 77% token reduction target

- **MCP Servers (Phase 1)** - Cache and pattern serving
  - `sage-research` server uses cache manager
  - `sage-context-optimizer` server serves filtered patterns
  - `sage-specification` server uses progressive loading

**External Integrations:**

- **Git** - Pattern extraction respects `.gitignore`
  - Only extract from tracked files
  - Incremental extraction on file changes
  - Integration with pre-commit hooks (optional)

- **IDEs** - Pattern hints (future)
  - VSCode extension could show extracted patterns
  - Real-time pattern validation
  - Quick-fix suggestions based on patterns

### API Design

**Cache Manager API:**

```typescript
interface CacheManager {
  // Get cached research (null if miss or expired)
  get(topic: string): Promise<CacheEntry | null>;

  // Set cache entry
  set(topic: string, findings: ResearchFindings): Promise<void>;

  // Check if cache exists and is valid
  has(topic: string): Promise<boolean>;

  // Invalidate specific cache entry
  invalidate(topic: string): Promise<void>;

  // Clear all cache entries
  clear(): Promise<void>;

  // Get cache statistics
  stats(): Promise<CacheStats>;

  // Cleanup expired entries
  cleanup(): Promise<number>;  // Returns count of removed entries
}
```

**Pattern Extractor API:**

```typescript
interface PatternExtractor {
  // Extract patterns from repository
  extract(rootDir: string): Promise<RepositoryPatterns>;

  // Extract patterns from specific files
  extractFromFiles(files: string[]): Promise<RepositoryPatterns>;

  // Validate extracted patterns
  validate(patterns: RepositoryPatterns): ValidationResult;

  // Merge pattern sets
  merge(
    base: RepositoryPatterns,
    update: RepositoryPatterns
  ): RepositoryPatterns;
}
```

**Progressive Loader API:**

```typescript
interface ProgressiveLoader {
  // Load patterns for specific context
  loadForContext(context: TaskContext): Promise<RelevantPatterns>;

  // Filter patterns by file type
  filterByFileType(
    patterns: RepositoryPatterns,
    fileType: FileType
  ): Patterns;

  // Filter patterns by feature
  filterByFeature(
    patterns: Patterns,
    feature: string
  ): Patterns;
}
```

**Data Contracts:**

```typescript
// Cache Entry
interface CacheEntry {
  topic: string;
  timestamp: string;  // ISO 8601
  expiresAt: string;  // ISO 8601
  findings: ResearchFindings;
  metadata: {
    tokenCount: number;
    queryTime: number;  // milliseconds
    sources: string[];  // URLs
  };
}

// Repository Patterns
interface RepositoryPatterns {
  naming: {
    python?: NamingConventions;
    typescript?: NamingConventions;
    javascript?: NamingConventions;
  };
  typing: {
    python?: TypePatterns;
    typescript?: TypePatterns;
  };
  testing: {
    python?: TestPatterns;
    typescript?: TestPatterns;
  };
  errorHandling: ErrorHandlingPatterns;
  architecture: ArchitecturePatterns;
  metadata: {
    extractedAt: string;
    fileCount: number;
    confidence: number;  // 0-1
  };
}

// Task Context
interface TaskContext {
  fileType: 'python' | 'typescript' | 'javascript' | 'rust' | 'go';
  feature: string;  // 'auth', 'api', 'ui', 'data'
  domain: string;   // 'frontend', 'backend', 'infra'
}
```

---

## üß™ Testing Strategy

### Test Approach

**Testing Pyramid:**

- **Unit Tests: 80% coverage target** - Core caching and extraction logic
  - Cache manager operations (get, set, invalidate, cleanup)
  - AST parsing for each language (Python, TypeScript, JavaScript)
  - Pattern confidence scoring
  - TTL calculation and expiration checking
  - Progressive loader filtering logic

- **Integration Tests: 90% coverage target** - End-to-end workflows
  - `/sage.init` ‚Üí pattern extraction ‚Üí storage
  - `/sage.intel` ‚Üí cache miss ‚Üí fetch ‚Üí store ‚Üí cache hit
  - `/sage.specify` ‚Üí progressive loading ‚Üí specification generation
  - Cache expiration and cleanup
  - Pattern extraction on real repositories

- **Performance Tests: 100% of benchmarks** - Token and speed validation
  - Research token usage (180K ‚Üí 8K target)
  - Cache hit speed (<1s target)
  - Pattern extraction time (<2min for large repos)
  - Progressive loading overhead (<50ms target)

**Testing Framework:**

- **Primary:** Vitest (from Phase 1, consistent tooling)
- **Mocking:** Vitest built-in + manual file system mocks
- **Test Data:** Real repository samples (Python, TypeScript, hybrid)

### Test Scenarios

**Critical Scenarios:**

1. **Cache Hit - Identical Research Query**

   ```typescript
   // First query (cache miss)
   const result1 = await performResearch('rag-frameworks-2025');
   expect(result1.fromCache).toBe(false);
   expect(result1.tokenCount).toBeGreaterThan(100000);

   // Second query (cache hit)
   const result2 = await performResearch('rag-frameworks-2025');
   expect(result2.fromCache).toBe(true);
   expect(result2.tokenCount).toBeLessThan(1000);
   expect(result2.time).toBeLessThan(1000);  // < 1 second
   ```

2. **Cache Expiration - 30 Days Old**

   ```typescript
   // Cache entry with old timestamp
   const oldEntry = {
       timestamp: '2025-10-01T00:00:00Z',  // 43 days ago
       expiresAt: '2025-11-01T00:00:00Z',  // Expired
       findings: { /* data */ }
   };

   await setCacheEntry('old-topic', oldEntry);

   // Should return null (expired)
   const result = await getCachedResearch('old-topic');
   expect(result).toBeNull();
   ```

3. **Pattern Extraction - Python Repository**

   ```typescript
   const patterns = await extractPatterns('./test-repos/python-repo');

   expect(patterns.naming.python.functions).toBe('snake_case');
   expect(patterns.naming.python.classes).toBe('PascalCase');
   expect(patterns.typing.python.unionSyntax).toBe('pipe');  // str | int
   expect(patterns.testing.python.framework).toBe('pytest');
   expect(patterns.metadata.confidence).toBeGreaterThan(0.8);
   ```

4. **Progressive Loading - Python Auth Feature**

   ```typescript
   const context = {
       fileType: 'python',
       feature: 'auth',
       domain: 'backend'
   };

   const allPatterns = await loadAllPatterns();
   const relevantPatterns = await loadForContext(context);

   // Should only load Python + auth patterns
   expect(relevantPatterns).toHaveProperty('naming.python');
   expect(relevantPatterns).toHaveProperty('security.authentication');
   expect(relevantPatterns).not.toHaveProperty('naming.typescript');
   expect(relevantPatterns).not.toHaveProperty('ui.react');

   // Verify reduction
   const allSize = JSON.stringify(allPatterns).length;
   const relevantSize = JSON.stringify(relevantPatterns).length;
   expect(relevantSize / allSize).toBeLessThan(0.15);  // 85%+ reduction
   ```

5. **Cache Storage Limit - 100MB Exceeded**

   ```typescript
   // Fill cache beyond 100MB
   await fillCacheToSize(110 * 1024 * 1024);  // 110MB

   // Trigger cleanup
   await cacheManager.cleanup();

   // Verify size under limit
   const stats = await cacheManager.stats();
   expect(stats.totalSize).toBeLessThan(100 * 1024 * 1024);  // < 100MB
   expect(stats.message).toContain('LRU eviction');
   ```

**Edge Cases:**

- **Empty repository** - Pattern extraction returns defaults with low confidence
- **Mixed case naming** - Detector finds predominant pattern (snake_case 80%, camelCase 20%)
- **Corrupted cache file** - Auto-delete, fallback to fresh fetch, log error
- **Very large file (10K+ lines)** - AST parsing timeouts handled gracefully
- **Cache during offline mode** - Uses existing cache, displays "offline" warning if expired
- **Concurrent cache writes** - File locking prevents corruption (Node.js fs.promises)
- **Non-standard patterns** - Confidence score < 0.6, suggest manual review

**Performance Tests:**

- **Token Measurement:**

  ```typescript
  const baseline = await measureTokens(() => performResearch('topic', { noCache: true }));
  expect(baseline.tokens).toBeGreaterThan(150000);

  const withCache = await measureTokens(() => performResearch('topic'));
  expect(withCache.tokens).toBeLessThan(10000);  // 96% reduction
  ```

- **Speed Benchmark:**

  ```typescript
  const times = [];
  for (let i = 0; i < 10; i++) {
      const start = Date.now();
      await getCachedResearch('cached-topic');
      times.push(Date.now() - start);
  }

  const avgTime = times.reduce((a, b) => a + b) / times.length;
  expect(avgTime).toBeLessThan(10);  // < 10ms average
  ```

### Quality Metrics

- **Code Coverage:** Target 80% (unit), 90% (integration)
- **Test Execution Time:** < 60 seconds (unit), < 3 minutes (integration)
- **Test Reliability:** > 99.5% pass rate
- **Performance Regression:** Alert if research > 10K tokens or cache hit > 1s

---

## üìã Implementation Recommendations

### Phase 2.1: Pattern Extraction Foundation (Week 3, Days 1-3)

**Deliverables:**

1. **Python AST Extractor** - `pattern-extractor-python.ts`
   - Naming conventions (functions, classes, constants)
   - Type patterns (union syntax, generics)
   - Testing patterns (framework, file naming, fixtures)
   - Confidence scoring algorithm

2. **TypeScript ts-morph Extractor** - `pattern-extractor-typescript.ts`
   - Naming conventions (functions, classes, interfaces)
   - Type patterns (type aliases, generics)
   - Testing patterns (Jest, Vitest detection)

3. **Pattern Storage** - `.sage/agent/examples/repository-patterns.ts`
   - TypeScript export format
   - JSON schema validation
   - Merge strategy for incremental updates

4. **Extraction Tests** - `pattern-extractor.test.ts`
   - Test on 3 real repositories (Python, TypeScript, hybrid)
   - Validate 80%+ capture rate
   - Confidence score validation

**Dependencies:**

- Python `ast` module (standard library)
- ts-morph npm package
- Test repositories prepared

**Success Criteria:**

- 80%+ pattern capture rate validated
- Confidence scores accurate (manual review)
- Extraction completes in <2min for 1000+ files
- TypeScript patterns file generated correctly

### Phase 2.2: Research Caching System (Week 3, Days 4-5)

**Deliverables:**

1. **Cache Manager** - `servers/sage-research/cache-manager.ts`
   - get, set, invalidate, clear, stats, cleanup methods
   - 30-day TTL with expiration checking
   - Age display formatting
   - JSON schema validation (Zod)

2. **Cache Manifest** - `.sage/agent/research/CACHE_MANIFEST.json`
   - Tracks all cache entries (topic, timestamp, size, access count)
   - Updated on every cache operation
   - Used for LRU eviction

3. **Storage Management** - `cache-storage.ts`
   - 100MB size limit enforcement
   - LRU eviction policy
   - Disk usage monitoring
   - Cleanup scheduling (optional background task)

4. **Integration with `/sage.intel`**
   - Check cache before research operations
   - Display cache status ("Cached 2 hours ago" or "Fetching fresh...")
   - `--no-cache` flag to force fresh fetch

**Dependencies:**

- Node.js fs/promises module
- Zod (from Phase 1)
- `/sage.intel` command (existing)

**Success Criteria:**

- Cache hit: <1s, <1K tokens
- Cache miss: stores result correctly
- TTL expiration working (30 days)
- Storage limit enforced (100MB)
- Manual invalidation working

### Phase 2.3: Progressive Loading (Week 4, Days 1-3)

**Deliverables:**

1. **Progressive Loader** - `servers/sage-context-optimizer/progressive-loader.ts`
   - Context-based filtering (file type, feature, domain)
   - Dynamic import() integration
   - Pattern caching for session
   - 90%+ reduction validation

2. **File Type Mapping** - `file-type-patterns.ts`
   - Explicit mapping: python ‚Üí [python naming, typing, testing]
   - TypeScript ‚Üí [typescript naming, typing]
   - JavaScript ‚Üí [javascript naming]

3. **Feature Mapping** - `feature-patterns.ts`
   - auth ‚Üí [security, authentication patterns]
   - api ‚Üí [REST, validation patterns]
   - ui ‚Üí [React, CSS patterns]

4. **Integration with `/sage.specify`**
   - Load only relevant patterns before spec generation
   - Measure token reduction (target: 77%)
   - Cache loaded patterns for session

**Dependencies:**

- Phase 2.1 complete (patterns extracted)
- ES6 dynamic import() support
- `/sage.specify` command (existing)

**Success Criteria:**

- Progressive loading reduces patterns by 90%+
- Filtering overhead < 50ms
- Specification token usage ‚â§ 20K (77% reduction)
- No pattern mismatch errors

### Phase 2.4: Integration & Metrics Validation (Week 4, Days 4-5)

**Deliverables:**

1. **Full Integration Testing**
   - End-to-end: init ‚Üí research (cache miss) ‚Üí research (cache hit) ‚Üí specify
   - Token measurement at each step
   - Performance benchmarking

2. **MCP Server Creation**
   - `servers/sage-research/` - Research with caching
   - `servers/sage-context-optimizer/` - Pattern extraction and progressive loading
   - MCP tool handlers for each operation

3. **Documentation**
   - `CACHING.md` - Cache system explanation
   - `PATTERN_EXTRACTION.md` - Extraction process and patterns
   - `PHASE_2_RESULTS.md` - Metrics and validation results

4. **Metrics Dashboard** (optional)
   - Token usage tracking
   - Cache hit rate
   - Pattern extraction statistics

**Success Criteria:**

- Research: 180K ‚Üí 8K (96% reduction) validated
- Specification: 80K ‚Üí 18K (77% reduction) validated
- Cache hit rate > 80% after initial usage
- All integration tests passing
- Documentation complete

### Risk Mitigation

| Risk | Probability | Impact | Mitigation Strategy |
|------|-------------|--------|---------------------|
| Pattern extraction <80% accuracy | Medium | High | Confidence scoring, manual review option, fallback to default patterns, iterative improvement |
| Cache invalidation issues | Low | Medium | Clear timestamp display, 30-day TTL, manual `--no-cache` flag, documentation of cache behavior |
| Storage limits exceeded | Low | Low | 100MB hard limit with alerts at 80MB, LRU eviction automatic, cleanup command available |
| Progressive loading confusion | Medium | Medium | Explicit file-type ‚Üí pattern mapping, validation tests, debug mode showing loaded patterns |
| Cache corruption | Low | Medium | Zod schema validation on every read, auto-delete corrupted files, fallback to fresh fetch, logging |
| AST parsing errors | Low | Medium | Try-catch around parsing, skip problematic files, log errors, partial results acceptable |
| Performance regression | Low | High | Continuous benchmarking, alerts on token > target, optimize bottlenecks iteratively |

---

## üîó Research References

**Technical Documentation:**

- Python AST Module: <https://docs.python.org/3/library/ast.html>
- ts-morph Library: <https://ts-morph.com/>
- Tree-sitter: <https://tree-sitter.github.io/tree-sitter/>
- Next.js Lazy Loading: <https://nextjs.org/docs/app/guides/lazy-loading>
- ES6 Dynamic Import: <https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/import>

**Best Practices:**

- Cache Invalidation Strategies: <https://sparkco.ai/blog/deep-dive-into-cache-invalidation-agents-in-2025>
- AST Parsing Guide: <https://rotemtam.com/2020/08/13/python-ast/>
- Progressive Loading Patterns: <https://www.patterns.dev/vanilla/import-on-interaction/>
- Context-Aware Patterns: <https://erkanyasun.medium.com/introducing-the-contextual-adapter-pattern>

**Competitive Research:**

- KVzip Context Compression: <https://techxplore.com/news/2025-11-ai-tech-compress-llm-chatbot.html>
- LLMLingua Compression: <https://www.microsoft.com/en-us/research/blog/llmlingua-innovating-llm-efficiency-with-prompt-compression/>
- Cache-Craft RAG Caching: <https://dl.acm.org/doi/10.1145/3725273>
- Mem0 Memory Systems: <https://mem0.ai/blog/llm-chat-history-summarization-guide-2025>

**Academic Research:**

- Acon Framework: <https://arxiv.org/html/2510.00615v1>
- Repository Pattern Analysis: <https://arxiv.org/html/2505.14394v1>
- Knowledge Graphs for Code: <https://arxiv.org/html/2510.10290>

---

## üéØ Next Steps

1. **Generate Specification**

   ```bash
   /sage.specify context-optimization-caching
   ```

   Create formal specification from this research.
   Output: `docs/specs/context-optimization-caching/spec.md`

2. **Create Implementation Plan**

   ```bash
   /sage.plan context-optimization-caching
   ```

   Develop detailed technical implementation plan.
   Output: `docs/specs/context-optimization-caching/plan.md`

3. **Break Down Tasks**

   ```bash
   /sage.tasks context-optimization-caching
   ```

   Create actionable task breakdown with tickets.
   Output: `.sage/tickets/index.json` (tickets created)

4. **Execute Implementation**

   ```bash
   /sage.implement [ticket-id]
   ```

   Execute implementation following Ticket Clearance Methodology.

---

**Feature Request:** docs/features/context-optimization-caching.md
**Status:** Research complete - Ready for specification generation
**Research Quality:** High - Comprehensive research with proven techniques, competitive analysis, and detailed technical recommendations
